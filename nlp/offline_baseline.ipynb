{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "offline_baseline.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VadimKaryakin/mlcup/blob/main/nlp/offline_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_EesdXNiL3o"
      },
      "source": [
        "Загружаем скачанный классификатор токсичности:"
      ],
      "id": "H_EesdXNiL3o"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_A5vMz7oIxd"
      },
      "source": [
        "!pip install transformers"
      ],
      "id": "X_A5vMz7oIxd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuWt0dNcnkaI",
        "outputId": "d11e56d5-897b-4082-90fe-94dfe4100593",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "zuWt0dNcnkaI",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdQaKacUiL3-"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "  \n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/trained_roberta/trained_roberta/\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/trained_roberta/trained_roberta/\").cuda()\n",
        "\n",
        "TOXIC_CLASS=-1\n",
        "TOKENIZATION_TYPE='sentencepiece'\n"
      ],
      "id": "DdQaKacUiL3-",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEExUOOJiL4C"
      },
      "source": [
        "Ниже функции для применения классификатора"
      ],
      "id": "nEExUOOJiL4C"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLNuQ2tOiL4D"
      },
      "source": [
        "from torch import softmax, sigmoid\n",
        "import numpy as np\n",
        "\n",
        "ALLOWED_ALPHABET=list(map(chr, range(ord('а'), ord('я') + 1)))\n",
        "ALLOWED_ALPHABET.extend(map(chr, range(ord('a'), ord('z') + 1)))\n",
        "ALLOWED_ALPHABET.extend(list(map(str.upper, ALLOWED_ALPHABET)))\n",
        "ALLOWED_ALPHABET = set(ALLOWED_ALPHABET)\n",
        "\n",
        "def logits_to_toxic_probas(logits):\n",
        "    if logits.shape[-1] > 1:\n",
        "        activation = lambda x: softmax(x, -1)\n",
        "    else:\n",
        "        activation = sigmoid\n",
        "    return activation(logits)[:, TOXIC_CLASS].cpu().detach().numpy()\n",
        "\n",
        "def is_word_start(token):\n",
        "    if TOKENIZATION_TYPE == 'sentencepiece':\n",
        "        return token.startswith('▁')\n",
        "    if TOKENIZATION_TYPE == 'bert':\n",
        "        return not token.startswith('##')\n",
        "    raise ValueError(\"Unknown tokenization type\")\n",
        "\n",
        "def normalize(sentence, max_tokens_per_word=20):\n",
        "    sentence = ''.join(map(lambda c: c if c.isalpha() else ' ', sentence.lower()))\n",
        "    ids = tokenizer(sentence)['input_ids']\n",
        "    tokens = tokenizer.convert_ids_to_tokens(ids)[1:-1]\n",
        "    \n",
        "    result = []\n",
        "    num_continuation_tokens = 0\n",
        "    for token in tokens:\n",
        "        if not is_word_start(token):\n",
        "            num_continuation_tokens += 1\n",
        "            if num_continuation_tokens < max_tokens_per_word:\n",
        "                result.append(token.lstrip('#▁'))\n",
        "        else:\n",
        "            num_continuation_tokens = 0\n",
        "            result.extend([' ', token.lstrip('▁#')])\n",
        "    \n",
        "    return ''.join(result).strip()\n",
        "\n",
        "def iterate_batches(data, batch_size=40):\n",
        "    batch = []\n",
        "    for x in data:\n",
        "        batch.append(x)\n",
        "        if len(batch) >= batch_size:\n",
        "            yield batch\n",
        "            batch = []\n",
        "    if len(batch) > 0:\n",
        "        yield batch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "def predict_toxicity(sentences, batch_size=5, threshold=0.5, return_scores=False, verbose=True, device='cuda'):\n",
        "    results = []\n",
        "    tqdm_fn = tqdm if verbose else lambda x, total: x\n",
        "    for batch in tqdm_fn(iterate_batches(sentences, batch_size), total=np.ceil(len(sentences) / batch_size)):\n",
        "        normlized = [normalize(sent, max_tokens_per_word=5) for sent in batch]\n",
        "        tokenized = tokenizer(normlized, return_tensors='pt', padding=True, max_length=512, truncation=True)\n",
        "        \n",
        "        logits = model.to(device)(**{key: val.to(device) for key, val in tokenized.items()}).logits\n",
        "        preds = logits_to_toxic_probas(logits)\n",
        "        if not return_scores:\n",
        "            preds = preds >= threshold\n",
        "        results.extend(preds)\n",
        "    return results\n"
      ],
      "id": "KLNuQ2tOiL4D",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBpyDG8GiL4E"
      },
      "source": [
        "Читаем тестовый набор"
      ],
      "id": "cBpyDG8GiL4E"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDuCtDpBiL4G",
        "outputId": "e95c2b60-0643-402e-e743-5e27faf5bba6"
      },
      "source": [
        "texts = []\n",
        "with open('/content/drive/MyDrive/public_testset.txt', 'rt') as f:\n",
        "    for line in f:\n",
        "        texts.append(normalize(line)) "
      ],
      "id": "zDuCtDpBiL4G",
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8VTZ76TiL4H"
      },
      "source": [
        "Вычисляем токсичность отдельных слов"
      ],
      "id": "N8VTZ76TiL4H"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpsLhoAZiL4I",
        "outputId": "94c1e83f-787a-417f-f9cc-9f25d56b44a0",
        "colab": {
          "referenced_widgets": [
            "f9a3d78c1c1e48a9bdbbd92a21b0e745"
          ]
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "words = set()\n",
        "for text in texts:\n",
        "    words.update(text.split())\n",
        "words = sorted(words)\n",
        "\n",
        "with torch.inference_mode():\n",
        "    word_toxicities = predict_toxicity(words, batch_size=100, return_scores=True)\n",
        "    \n",
        "toxicity = dict(zip(words, word_toxicities))\n"
      ],
      "id": "JpsLhoAZiL4I",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9a3d78c1c1e48a9bdbbd92a21b0e745",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=221.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8pXvQbIiL4J"
      },
      "source": [
        "Ниже читаем эмбеддинги слов и описываем функции их обработки"
      ],
      "id": "J8pXvQbIiL4J"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "syBOotDKiL4K"
      },
      "source": [
        "import gensim\n",
        "from pymystem3 import Mystem\n",
        "\n",
        "stemmer = Mystem()"
      ],
      "id": "syBOotDKiL4K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoAa61VWiL4L"
      },
      "source": [
        "embs_file = np.load('/content/drive/MyDrive/trained_roberta/embeddings_with_lemmas.npz', allow_pickle=True)\n",
        "embs_vectors = embs_file['vectors']\n",
        "embs_vectors_normed = embs_vectors / np.linalg.norm(embs_vectors, axis=1, keepdims=True)\n",
        "embs_voc = embs_file['voc'].item()\n",
        "\n",
        "embs_voc_by_id = [None for i in range(len(embs_vectors))]\n",
        "for word, idx in embs_voc.items():\n",
        "    if embs_voc_by_id[idx] is None:\n",
        "        embs_voc_by_id[idx] = word"
      ],
      "id": "uoAa61VWiL4L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06i0-5ociL4L"
      },
      "source": [
        "def get_w2v_indicies(a):\n",
        "    res = []\n",
        "    if isinstance(a, str):\n",
        "        a = a.split()\n",
        "    for w in a:\n",
        "        if w in embs_voc:\n",
        "            res.append(embs_voc[w])\n",
        "        else:\n",
        "            lemma = stemmer.lemmatize(w)[0]\n",
        "            res.append(embs_voc.get(lemma, None))\n",
        "    return res\n",
        "\n",
        "def calc_embs(words):\n",
        "    words = ' '.join(map(normalize, words))\n",
        "    inds = get_w2v_indicies(words)\n",
        "    return [None if i is None else embs_vectors[i] for i in inds]"
      ],
      "id": "06i0-5ociL4L",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3jqM_luiL4M"
      },
      "source": [
        "Сложим эмбеддинги нетоксичных слов в kd-дерево, чтобы можно было близко искать ближайших соседей"
      ],
      "id": "D3jqM_luiL4M"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAn3ZTfyiL4N"
      },
      "source": [
        "nontoxic_emb_inds = [ind for word, ind in embs_voc.items() if toxicity.get(word, 1.0) <= 0.5]\n",
        "embs_vectors_normed_nontoxic = embs_vectors_normed[nontoxic_emb_inds]"
      ],
      "id": "tAn3ZTfyiL4N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXU6wpYriL4N"
      },
      "source": [
        "from sklearn.neighbors import KDTree\n",
        "embs_tree = KDTree(embs_vectors_normed_nontoxic, leaf_size=20)"
      ],
      "id": "BXU6wpYriL4N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Mar9W5CiL4N"
      },
      "source": [
        "Функция находит самое близкое нетоксичное слово по предпосчитанным эмбеддингам слов"
      ],
      "id": "5Mar9W5CiL4N"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHs-WJ99iL4O"
      },
      "source": [
        "from functools import lru_cache\n",
        "\n",
        "@lru_cache()\n",
        "def find_closest_nontoxic(word, threshold=0.5, allow_self=False):\n",
        "    if toxicity.get(word, 1.0) <= threshold:\n",
        "        return word\n",
        "    \n",
        "    if word not in toxicity and word not in embs_voc:\n",
        "        return None\n",
        "    \n",
        "    threshold = min(toxicity.get(word, threshold), threshold)\n",
        "    word = normalize(word)\n",
        "    word_emb = calc_embs([word])\n",
        "    if word_emb is None or word_emb[0] is None:\n",
        "        return None\n",
        "    \n",
        "    for i in embs_tree.query(word_emb)[1][0]:\n",
        "        other_word = embs_voc_by_id[nontoxic_emb_inds[i]]\n",
        "        if (other_word != word or allow_self) and toxicity.get(other_word, 1.0) <= threshold:\n",
        "            return other_word\n",
        "    return None"
      ],
      "id": "AHs-WJ99iL4O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyDdslFHiL4O"
      },
      "source": [
        "Заменяем токсичные слова на ближайшие по эмбеддингам не-токсичные"
      ],
      "id": "XyDdslFHiL4O"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-8ZvPgtiL4P"
      },
      "source": [
        "def detox(line):\n",
        "    words = normalize(line).split()\n",
        "    fixed_words = [find_closest_nontoxic(word, allow_self=True) or '' for word in words]\n",
        "    return ' '.join(fixed_words)"
      ],
      "id": "o-8ZvPgtiL4P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqoKGHF_iL4P",
        "outputId": "ea4f0ff0-5e85-42a0-dbfb-d621af0338ae",
        "colab": {
          "referenced_widgets": [
            "02f2386b32d2445c8007a8acf23f0a9c"
          ]
        }
      },
      "source": [
        "fixed_texts = list(map(detox, tqdm(texts)))"
      ],
      "id": "vqoKGHF_iL4P",
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02f2386b32d2445c8007a8acf23f0a9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=2500.0), HTML(value='')))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4Om2UBjiL4Q"
      },
      "source": [
        "запишем результат в файл"
      ],
      "id": "b4Om2UBjiL4Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJdalS-7iL4Q"
      },
      "source": [
        "with open('baseline_fixed.txt', 'wt') as f:\n",
        "    for text in fixed_texts:\n",
        "        print(text, file=f)"
      ],
      "id": "yJdalS-7iL4Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9hNDCTziL4Q"
      },
      "source": [
        "Скор, если никак не изменять комментарии:"
      ],
      "id": "V9hNDCTziL4Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4oUOOHwiL4R"
      },
      "source": [
        "!python3.7 score.py /content/drive/MyDrive/public_testset.txt public_testset.short.txt  --embeddings /content/drive/MyDrive/trained_roberta/embeddings_with_lemmas.npz --lm lm.binary --model ./content/drive/MyDrive/trained_roberta/trained_roberta/ --device cuda --score -"
      ],
      "id": "c4oUOOHwiL4R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veZNqkCRiL4R"
      },
      "source": [
        "Скор бейзлайна:"
      ],
      "id": "veZNqkCRiL4R"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDyjZxIeiL4S"
      },
      "source": [
        "!python3.7 score.py /content/drive/MyDrive/public_testset.txt baseline_fixed.txt  --embeddings /content/drive/MyDrive/trained_roberta/embeddings_with_lemmas.npz --lm lm.binary --model ./content/drive/MyDrive/trained_roberta/trained_roberta/ --device cuda --score -"
      ],
      "id": "PDyjZxIeiL4S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAxLrbjkiL4S"
      },
      "source": [
        "Сохраним данные для бейзлайна online-задачи"
      ],
      "id": "HAxLrbjkiL4S"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBT71nlPiL4S"
      },
      "source": [
        "!mkdir -p online_baseline"
      ],
      "id": "GBT71nlPiL4S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoSIDzxaiL4T"
      },
      "source": [
        "import pickle as pkl\n",
        "\n",
        "with open('./online_baseline/data.pkl', 'wb') as f:\n",
        "    pkl.dump(toxicity, f)\n",
        "    pkl.dump(nontoxic_emb_inds, f)"
      ],
      "id": "hoSIDzxaiL4T",
      "execution_count": null,
      "outputs": []
    }
  ]
}